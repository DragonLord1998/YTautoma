{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "A100"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé¨ YTautoma - YouTube Shorts Automation\n",
                "\n",
                "Generate 60-second YouTube Shorts using local AI models:\n",
                "- **Story**: Gemma 3 (via Ollama)\n",
                "- **Images**: Z-Image-Turbo\n",
                "- **Video**: Wan 2.2\n",
                "- **Voice**: Edge-TTS (simple) or VibeVoice (advanced)\n",
                "\n",
                "**Works on**: Colab (A100), RunPod, Lambda Labs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Clone & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Auto-detect workspace\n",
                "if os.path.exists('/content'):\n",
                "    WORKSPACE = '/content'\n",
                "elif os.path.exists('/workspace'):\n",
                "    WORKSPACE = '/workspace'\n",
                "else:\n",
                "    WORKSPACE = os.path.expanduser('~')\n",
                "\n",
                "os.chdir(WORKSPACE)\n",
                "print(f'Workspace: {WORKSPACE}')\n",
                "\n",
                "# Clone repo\n",
                "!git clone https://github.com/DragonLord1998/YTautoma.git 2>/dev/null || (cd YTautoma && git pull)\n",
                "os.chdir('YTautoma')\n",
                "PROJECT_DIR = os.getcwd()\n",
                "print(f'Project: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Python dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q git+https://github.com/huggingface/diffusers\n",
                "!pip install -q edge-tts  # Simple TTS that always works\n",
                "!pip install -q flash-attn --no-build-isolation 2>/dev/null || echo 'flash-attn optional'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama + Pull Model\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "import subprocess, time\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
                "time.sleep(5)\n",
                "\n",
                "!ollama pull gemma3:4b"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Wan 2.2 (for video generation)\n",
                "!mkdir -p models\n",
                "!git clone https://github.com/Wan-Video/Wan2.2.git models/Wan2.2 2>/dev/null || echo 'Already exists'\n",
                "!pip install -q -r models/Wan2.2/requirements.txt\n",
                "\n",
                "# Download TI2V-5B model (smaller, works on most GPUs)\n",
                "!pip install -q \"huggingface_hub[cli]\"\n",
                "!huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir models/Wan2.2-TI2V-5B"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create .env configuration\n",
                "import os\n",
                "PROJECT_DIR = os.getcwd()\n",
                "\n",
                "env_content = f\"\"\"OLLAMA_MODEL=gemma3:4b\n",
                "OLLAMA_BASE_URL=http://localhost:11434\n",
                "\n",
                "ZIMAGE_MODEL=Tongyi-MAI/Z-Image-Turbo\n",
                "ZIMAGE_DEVICE=cuda\n",
                "\n",
                "WAN_REPO_PATH={PROJECT_DIR}/models/Wan2.2\n",
                "WAN_MODEL_PATH={PROJECT_DIR}/models/Wan2.2-TI2V-5B\n",
                "WAN_T5_CPU=true\n",
                "WAN_OFFLOAD_MODEL=true\n",
                "\n",
                "# Using edge-tts instead of VibeVoice (simpler, always works)\n",
                "TTS_ENGINE=edge\n",
                "\n",
                "LOW_VRAM_MODE=true\n",
                "TORCH_DTYPE=float16\n",
                "\"\"\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(env_content)\n",
                "\n",
                "print('‚úÖ Configuration saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Generate YouTube Short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test: Story only (no GPU needed)\n",
                "!python main.py --story-only -c mystery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate story + images (skip video for speed)\n",
                "!python main.py --images-only -c horror"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline with video (requires A100 or better)\n",
                "!python main.py -c sci-fi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ View & Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List outputs\n",
                "!find output -name '*.mp4' -o -name '*.png' -o -name '*.json' | head -30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View generated images\n",
                "from IPython.display import Image, display\n",
                "import glob\n",
                "\n",
                "images = sorted(glob.glob('output/**/base_image.png', recursive=True))\n",
                "for img in images[:6]:\n",
                "    print(img)\n",
                "    display(Image(filename=img, width=300))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download video (Colab only)\n",
                "import os, glob\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "    videos = glob.glob('output/**/*.mp4', recursive=True)\n",
                "    if videos:\n",
                "        latest = max(videos, key=lambda x: os.path.getmtime(x))\n",
                "        print(f'Downloading: {latest}')\n",
                "        files.download(latest)\n",
                "    else:\n",
                "        print('No video yet. Run full pipeline first!')\n",
                "except ImportError:\n",
                "    print('Not in Colab. Videos at:')\n",
                "    !find output -name '*.mp4'"
            ]
        }
    ]
}