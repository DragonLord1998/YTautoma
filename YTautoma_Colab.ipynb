{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "A100"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé¨ YTautoma - YouTube Shorts Automation\n",
                "\n",
                "Generate 60-second YouTube Shorts using local AI models:\n",
                "- **Story**: Gemma 3 (via Ollama)\n",
                "- **Images**: Z-Image-Turbo\n",
                "- **Video**: Wan 2.2\n",
                "- **Voice**: VibeVoice\n",
                "\n",
                "**Requirements**: A100 GPU (40GB) recommended"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone YTautoma\n",
                "!git clone https://github.com/DragonLord1998/YTautoma.git\n",
                "%cd YTautoma"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q git+https://github.com/huggingface/diffusers\n",
                "!pip install -q flash-attn --no-build-isolation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "# Start Ollama in background\n",
                "import subprocess\n",
                "subprocess.Popen(['ollama', 'serve'])\n",
                "import time\n",
                "time.sleep(5)\n",
                "\n",
                "# Pull Gemma 3 (use smaller model for Colab)\n",
                "!ollama pull gemma3:4b"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Wan 2.2\n",
                "!mkdir -p models\n",
                "!git clone https://github.com/Wan-Video/Wan2.2.git models/Wan2.2\n",
                "!pip install -q -r models/Wan2.2/requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download Wan 2.2 TI2V-5B (smaller, works on Colab)\n",
                "!pip install -q \"huggingface_hub[cli]\"\n",
                "!huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir models/Wan2.2-TI2V-5B"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone VibeVoice\n",
                "!git clone https://github.com/microsoft/VibeVoice.git models/VibeVoice\n",
                "!pip install -q -e models/VibeVoice"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create .env configuration\n",
                "env_content = \"\"\"\n",
                "OLLAMA_MODEL=gemma3:4b\n",
                "OLLAMA_BASE_URL=http://localhost:11434\n",
                "\n",
                "ZIMAGE_MODEL=Tongyi-MAI/Z-Image-Turbo\n",
                "ZIMAGE_DEVICE=cuda\n",
                "\n",
                "WAN_REPO_PATH=/content/YTautoma/models/Wan2.2\n",
                "WAN_MODEL_PATH=/content/YTautoma/models/Wan2.2-TI2V-5B\n",
                "WAN_T5_CPU=true\n",
                "WAN_OFFLOAD_MODEL=true\n",
                "\n",
                "VIBEVOICE_REPO_PATH=/content/YTautoma/models/VibeVoice\n",
                "VIBEVOICE_MODEL=microsoft/VibeVoice-Realtime-0.5B\n",
                "VIBEVOICE_SPEAKER=Carter\n",
                "\n",
                "LOW_VRAM_MODE=true\n",
                "TORCH_DTYPE=float16\n",
                "\"\"\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(env_content)\n",
                "\n",
                "print(\"‚úÖ Configuration saved!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Generate YouTube Short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate story only (quick test)\n",
                "!python main.py --story-only -c mystery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate images only (no video)\n",
                "!python main.py --images-only -c horror"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline (requires A100)\n",
                "!python main.py -c sci-fi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Download Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List generated files\n",
                "!ls -la output/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download to your computer\n",
                "from google.colab import files\n",
                "import glob\n",
                "\n",
                "# Find latest video\n",
                "videos = glob.glob('output/**/*.mp4', recursive=True)\n",
                "if videos:\n",
                "    latest = max(videos, key=lambda x: os.path.getmtime(x))\n",
                "    files.download(latest)\n",
                "else:\n",
                "    print(\"No video found. Run the pipeline first!\")"
            ]
        }
    ]
}