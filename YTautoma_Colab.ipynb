{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "A100"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé¨ YTautoma - YouTube Shorts Automation\n",
                "\n",
                "Generate 60-second YouTube Shorts using local AI models.\n",
                "\n",
                "| Component | Model |\n",
                "|-----------|-------|\n",
                "| Story | Gemma 3 (Ollama) |\n",
                "| Images | Z-Image-Turbo |\n",
                "| Video | Wan 2.2 |\n",
                "| Voice | VibeVoice / Edge-TTS |\n",
                "\n",
                "**Works on**: RunPod, Colab (A100), Lambda Labs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ System Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install system dependencies\n",
                "!apt-get update -qq && apt-get install -y -qq ffmpeg\n",
                "!ffmpeg -version | head -1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upgrade PyTorch (run this, then RESTART RUNTIME before next cell)\n",
                "!pip install -q --upgrade typing_extensions torch torchvision\n",
                "print('‚úÖ Done! Now restart the runtime (Runtime > Restart runtime) and run the next cell')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify PyTorch (run after restart)\n",
                "import torch\n",
                "print(f'PyTorch {torch.__version__} | CUDA: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Auto-detect workspace\n",
                "WORKSPACE = '/content' if os.path.exists('/content') else '/workspace' if os.path.exists('/workspace') else os.path.expanduser('~')\n",
                "os.chdir(WORKSPACE)\n",
                "\n",
                "# Clone repo\n",
                "!git clone https://github.com/DragonLord1998/YTautoma.git 2>/dev/null || (cd YTautoma && git pull)\n",
                "os.chdir('YTautoma')\n",
                "PROJECT_DIR = os.getcwd()\n",
                "print(f'Project: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Python dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q git+https://github.com/huggingface/diffusers\n",
                "!pip install -q edge-tts easydict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama + Gemma 3\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "import subprocess, time\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
                "time.sleep(5)\n",
                "\n",
                "!ollama pull gemma3:4b"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Wan 2.2 (video generation)\n",
                "!mkdir -p models\n",
                "!git clone https://github.com/Wan-Video/Wan2.2.git models/Wan2.2 2>/dev/null || echo 'Already cloned'\n",
                "!pip install -q -r models/Wan2.2/requirements.txt\n",
                "\n",
                "# Download model (10GB) - uncomment to enable video generation\n",
                "# !huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir models/Wan2.2-TI2V-5B"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup VibeVoice (high-quality TTS) - optional\n",
                "!git clone https://github.com/microsoft/VibeVoice.git models/VibeVoice 2>/dev/null || echo 'Already cloned'\n",
                "!cd models/VibeVoice && pip install -q -e ."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create .env configuration\n",
                "import os\n",
                "PROJECT_DIR = os.getcwd()\n",
                "\n",
                "env_content = f\"\"\"OLLAMA_MODEL=gemma3:4b\n",
                "OLLAMA_BASE_URL=http://localhost:11434\n",
                "\n",
                "ZIMAGE_MODEL=Tongyi-MAI/Z-Image-Turbo\n",
                "ZIMAGE_DEVICE=cuda\n",
                "\n",
                "WAN_REPO_PATH={PROJECT_DIR}/models/Wan2.2\n",
                "WAN_MODEL_PATH={PROJECT_DIR}/models/Wan2.2-TI2V-5B\n",
                "WAN_T5_CPU=true\n",
                "WAN_OFFLOAD_MODEL=true\n",
                "\n",
                "TTS_ENGINE=edge\n",
                "VIBEVOICE_REPO_PATH={PROJECT_DIR}/models/VibeVoice\n",
                "\n",
                "LOW_VRAM_MODE=true\n",
                "TORCH_DTYPE=float16\n",
                "\"\"\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(env_content)\n",
                "\n",
                "print('‚úÖ Configuration saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Generate YouTube Short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test: Story only\n",
                "!python main.py --story-only -c mystery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate story + images\n",
                "!python main.py --images-only -c horror"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline (requires Wan 2.2 model download)\n",
                "# !python main.py -c sci-fi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ View & Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View generated images\n",
                "from IPython.display import Image, display\n",
                "import glob\n",
                "\n",
                "images = sorted(glob.glob('output/**/base_image.png', recursive=True))[-6:]\n",
                "for img in images:\n",
                "    print(img.split('/')[-2])\n",
                "    display(Image(filename=img, width=250))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download outputs\n",
                "import os, glob\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "    !cd output && zip -r ../output.zip .\n",
                "    files.download('output.zip')\n",
                "except ImportError:\n",
                "    print('Find outputs at: ./output/')\n",
                "    !find output -name '*.mp4' -o -name '*.png' | head -20"
            ]
        }
    ]
}