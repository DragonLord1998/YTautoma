{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "A100"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé¨ YTautoma - YouTube Shorts Automation\n",
                "\n",
                "Generate 60-second YouTube Shorts using local AI models.\n",
                "\n",
                "**Works on**: Colab (A100), RunPod, Lambda Labs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ System Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install system dependencies\n",
                "!apt-get update -qq && apt-get install -y -qq ffmpeg\n",
                "!ffmpeg -version | head -1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upgrade PyTorch to 2.5+ (required for Z-Image)\n",
                "!pip install -q --upgrade torch torchvision\n",
                "import torch\n",
                "print(f'PyTorch {torch.__version__}')\n",
                "print(f'CUDA available: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone & Install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Auto-detect workspace\n",
                "if os.path.exists('/content'):\n",
                "    WORKSPACE = '/content'\n",
                "elif os.path.exists('/workspace'):\n",
                "    WORKSPACE = '/workspace'\n",
                "else:\n",
                "    WORKSPACE = os.path.expanduser('~')\n",
                "\n",
                "os.chdir(WORKSPACE)\n",
                "print(f'Workspace: {WORKSPACE}')\n",
                "\n",
                "# Clone repo\n",
                "!git clone https://github.com/DragonLord1998/YTautoma.git 2>/dev/null || (cd YTautoma && git pull)\n",
                "os.chdir('YTautoma')\n",
                "PROJECT_DIR = os.getcwd()\n",
                "print(f'Project: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Python dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q git+https://github.com/huggingface/diffusers\n",
                "!pip install -q edge-tts  # Simple TTS\n",
                "!pip install -q flash-attn --no-build-isolation 2>/dev/null || echo 'flash-attn optional'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama + Gemma 3\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "import subprocess, time\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
                "time.sleep(5)\n",
                "\n",
                "!ollama pull gemma3:4b"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Setup Wan 2.2 for video generation\n",
                "!mkdir -p models\n",
                "!git clone https://github.com/Wan-Video/Wan2.2.git models/Wan2.2 2>/dev/null || echo 'Already exists'\n",
                "!pip install -q -r models/Wan2.2/requirements.txt\n",
                "\n",
                "# Download TI2V-5B model (smaller, ~10GB)\n",
                "# Uncomment to enable video generation:\n",
                "# !pip install -q \"huggingface_hub[cli]\"\n",
                "# !huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir models/Wan2.2-TI2V-5B"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create .env configuration\n",
                "import os\n",
                "PROJECT_DIR = os.getcwd()\n",
                "\n",
                "env_content = f\"\"\"OLLAMA_MODEL=gemma3:4b\n",
                "OLLAMA_BASE_URL=http://localhost:11434\n",
                "\n",
                "ZIMAGE_MODEL=Tongyi-MAI/Z-Image-Turbo\n",
                "ZIMAGE_DEVICE=cuda\n",
                "\n",
                "WAN_REPO_PATH={PROJECT_DIR}/models/Wan2.2\n",
                "WAN_MODEL_PATH={PROJECT_DIR}/models/Wan2.2-TI2V-5B\n",
                "WAN_T5_CPU=true\n",
                "WAN_OFFLOAD_MODEL=true\n",
                "\n",
                "TTS_ENGINE=edge\n",
                "\n",
                "LOW_VRAM_MODE=true\n",
                "TORCH_DTYPE=float16\n",
                "\"\"\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(env_content)\n",
                "\n",
                "print('‚úÖ Configuration saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Generate YouTube Short"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test: Story only (no GPU needed)\n",
                "!python main.py --story-only -c mystery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate story + images\n",
                "!python main.py --images-only -c horror"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full pipeline (requires Wan 2.2 model downloaded)\n",
                "# !python main.py -c sci-fi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ View & Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List outputs\n",
                "!find output -name '*.png' -o -name '*.json' | head -30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View generated images\n",
                "from IPython.display import Image, display\n",
                "import glob\n",
                "\n",
                "images = sorted(glob.glob('output/**/base_image.png', recursive=True))\n",
                "for img in images[:6]:\n",
                "    print(img)\n",
                "    display(Image(filename=img, width=300))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download (Colab)\n",
                "import os, glob\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "    # Zip all outputs\n",
                "    !cd output && zip -r ../output.zip .\n",
                "    files.download('output.zip')\n",
                "except ImportError:\n",
                "    print('Not in Colab. Find outputs at: ./output/')"
            ]
        }
    ]
}